{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcolo delle grandezze utilizzate nei test di efficacia\n",
    "ORIGINAL_SIZE=568454            #dimensione originale\n",
    "reduction_factor=[0.1,0.3,0.5,0.7,1,1.3,1.5,1.7,2]  #fattori di riduzione utilizzati\n",
    "\n",
    "NEW_SIZE=[int(ORIGINAL_SIZE * x) for x in reduction_factor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path dei raw data\n",
    "path_MR=\"MR_raw_data.txt\"\n",
    "path_HIVE=\"HIVE_Raw_data.txt\"\n",
    "path_SPARK_CORE=\"SPARK_CORE_Raw_data.txt\"\n",
    "path_SPARK_SQL=\"SPARK_SQL_Raw_Data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file):\n",
    "    tempi_per_job={'job1':[],'job2':[]}\n",
    "    current_job=''\n",
    "    with open(file,'r') as f:\n",
    "        lines=f.readlines()\n",
    "        for line in lines:\n",
    "            value=line.strip().replace('\\n','').lower()\n",
    "            if 'job' in value:\n",
    "                value=value.replace(' ','')\n",
    "                current_job=value\n",
    "            elif 'real' in value:\n",
    "                value=value.strip().replace('\\n','').split('\\t')\n",
    "                if len(value)>1:\n",
    "                    time=value[1]\n",
    "                    tempi_per_job[current_job].append(time)\n",
    "    return tempi_per_job\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job1': ['0m28,374s',\n",
       "  '0m41,220s',\n",
       "  '0m45,507s',\n",
       "  '0m53,927s',\n",
       "  '1m0,502s',\n",
       "  '1m6,997s',\n",
       "  '1m12,927s',\n",
       "  '1m19,662s',\n",
       "  '1m26,289s'],\n",
       " 'job2': ['0m8,670s',\n",
       "  '0m8,763s',\n",
       "  '0m8,605s',\n",
       "  '0m8,744s',\n",
       "  '0m8,992s',\n",
       "  '0m9,059s',\n",
       "  '0m9,632s',\n",
       "  '0m9,723s',\n",
       "  '0m9,838s']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acquisizione dei dati\n",
    "dati_SPARK_CORE=extract_data(path_SPARK_CORE)\n",
    "dati_SPARK_SQL=extract_data(path_SPARK_SQL)\n",
    "dati_HIVE=extract_data(path_HIVE)\n",
    "dati_MR=extract_data(path_MR)\n",
    "dati_SPARK_SQL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creazione della mappatura k->dimensione attuale\n",
    "def create_mapping(keys,values,tgt_path):\n",
    "    mapping=dict()\n",
    "    for i in range(0,len(keys)):\n",
    "        mapping[keys[i]]=values[i]\n",
    "        \n",
    "    # covnersione mappa in json\n",
    "    json_data = json.dumps(mapping)\n",
    "\n",
    "    # Save the JSON data to a file\n",
    "    with open(tgt_path, \"w\") as file:\n",
    "        file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.3, 0.5, 0.7, 1, 1.3, 1.5, 1.7, 2]\n"
     ]
    }
   ],
   "source": [
    "#creazione di una viste  (colonne sono il fattore riduttivo) e di un mapping fattore_riduzione->dimensione attuale\n",
    "\n",
    "columns_view2=reduction_factor\n",
    "print(columns_view2)\n",
    "path_json_map='mapping_k_dim.json'\n",
    "create_mapping(columns_view2,NEW_SIZE,path_json_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_values(values):\n",
    "    out=[]\n",
    "        # Remove the 'm' and 's' characters and replace the comma with a dot\n",
    "    for v in values:\n",
    "        time_string = v.replace(\"m\", \"\").replace(\"s\", \"\").replace(\",\", \".\")\n",
    "\n",
    "        # Convert the string to a float\n",
    "        v = float(time_string)\n",
    "        print(\"Tempo corrente:\",v)\n",
    "        out.append(v)\n",
    "\n",
    "    return out\n",
    "\n",
    "def gen_rows(tempi,sistema):\n",
    "    row1=[sistema]\n",
    "    row2=[sistema]\n",
    "    print(\"Sistema\",sistema)\n",
    "    for k in tempi.keys():\n",
    "        print(\"Job:\",k)\n",
    "        if k=='job1':\n",
    "            row1.append('1')\n",
    "            values=tempi[k]\n",
    "            values=format_values(values)\n",
    "            row1.extend(values)\n",
    "            \n",
    "        elif k=='job2':\n",
    "            row2.append('2')\n",
    "            values=tempi[k]\n",
    "            values=format_values(values)\n",
    "            row2.extend(values)\n",
    "        \n",
    "    return [row1,row2]\n",
    "        \n",
    "def create_dataset(path,columns,data,systems):\n",
    "    out_put=[]\n",
    "    for i in range(0,len(data)):\n",
    "        tempi=data[i]\n",
    "        sistema=systems[i]\n",
    "        rows=gen_rows(tempi,sistema)\n",
    "        out_put=out_put+rows\n",
    "        print('dati correnti',out_put)\n",
    "    \n",
    "    pd.DataFrame(data=out_put,columns=columns).to_csv(path,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMERO COLONNE: 11\n",
      "Sistema SPARK_CORE\n",
      "Job: job1\n",
      "Tempo corrente: 9.583\n",
      "Tempo corrente: 11.824\n",
      "Tempo corrente: 16.012\n",
      "Tempo corrente: 18.426\n",
      "Tempo corrente: 21.965\n",
      "Tempo corrente: 25.213\n",
      "Tempo corrente: 27.975\n",
      "Tempo corrente: 29.687\n",
      "Tempo corrente: 33.084\n",
      "Job: job2\n",
      "Tempo corrente: 7.117\n",
      "Tempo corrente: 7.854\n",
      "Tempo corrente: 10.562\n",
      "Tempo corrente: 11.514\n",
      "Tempo corrente: 12.986\n",
      "Tempo corrente: 14.367\n",
      "Tempo corrente: 15.415\n",
      "Tempo corrente: 16.591\n",
      "Tempo corrente: 18.521\n",
      "dati correnti [['SPARK_CORE', '1', 9.583, 11.824, 16.012, 18.426, 21.965, 25.213, 27.975, 29.687, 33.084], ['SPARK_CORE', '2', 7.117, 7.854, 10.562, 11.514, 12.986, 14.367, 15.415, 16.591, 18.521]]\n",
      "Sistema HIVE\n",
      "Job: job1\n",
      "Tempo corrente: 40.496\n",
      "Tempo corrente: 55.58\n",
      "Tempo corrente: 15.187\n",
      "Tempo corrente: 119.261\n",
      "Tempo corrente: 135.07\n",
      "Tempo corrente: 152.103\n",
      "Tempo corrente: 159.95\n",
      "Tempo corrente: 212.162\n",
      "Tempo corrente: 220.862\n",
      "Job: job2\n",
      "Tempo corrente: 40.339\n",
      "Tempo corrente: 40.729\n",
      "Tempo corrente: 43.746\n",
      "Tempo corrente: 45.957\n",
      "Tempo corrente: 50.375\n",
      "Tempo corrente: 57.766\n",
      "Tempo corrente: 62.777\n",
      "Tempo corrente: 70.765\n",
      "Tempo corrente: 75.734\n",
      "dati correnti [['SPARK_CORE', '1', 9.583, 11.824, 16.012, 18.426, 21.965, 25.213, 27.975, 29.687, 33.084], ['SPARK_CORE', '2', 7.117, 7.854, 10.562, 11.514, 12.986, 14.367, 15.415, 16.591, 18.521], ['HIVE', '1', 40.496, 55.58, 15.187, 119.261, 135.07, 152.103, 159.95, 212.162, 220.862], ['HIVE', '2', 40.339, 40.729, 43.746, 45.957, 50.375, 57.766, 62.777, 70.765, 75.734]]\n",
      "Sistema MAP-REDUCE\n",
      "Job: job1\n",
      "Tempo corrente: 5.65\n",
      "Tempo corrente: 5.798\n",
      "Tempo corrente: 6.739\n",
      "Tempo corrente: 7.889\n",
      "Tempo corrente: 8.955\n",
      "Tempo corrente: 9.738\n",
      "Tempo corrente: 11.674\n",
      "Tempo corrente: 11.753\n",
      "Tempo corrente: 12.765\n",
      "Job: job2\n",
      "Tempo corrente: 3.058\n",
      "Tempo corrente: 3.921\n",
      "Tempo corrente: 4.065\n",
      "Tempo corrente: 5.461\n",
      "Tempo corrente: 5.77\n",
      "Tempo corrente: 6.018\n",
      "Tempo corrente: 6.861\n",
      "Tempo corrente: 7.267\n",
      "Tempo corrente: 7.698\n",
      "dati correnti [['SPARK_CORE', '1', 9.583, 11.824, 16.012, 18.426, 21.965, 25.213, 27.975, 29.687, 33.084], ['SPARK_CORE', '2', 7.117, 7.854, 10.562, 11.514, 12.986, 14.367, 15.415, 16.591, 18.521], ['HIVE', '1', 40.496, 55.58, 15.187, 119.261, 135.07, 152.103, 159.95, 212.162, 220.862], ['HIVE', '2', 40.339, 40.729, 43.746, 45.957, 50.375, 57.766, 62.777, 70.765, 75.734], ['MAP-REDUCE', '1', 5.65, 5.798, 6.739, 7.889, 8.955, 9.738, 11.674, 11.753, 12.765], ['MAP-REDUCE', '2', 3.058, 3.921, 4.065, 5.461, 5.77, 6.018, 6.861, 7.267, 7.698]]\n",
      "Sistema SPARK-SQL\n",
      "Job: job1\n",
      "Tempo corrente: 28.374\n",
      "Tempo corrente: 41.22\n",
      "Tempo corrente: 45.507\n",
      "Tempo corrente: 53.927\n",
      "Tempo corrente: 10.502\n",
      "Tempo corrente: 16.997\n",
      "Tempo corrente: 112.927\n",
      "Tempo corrente: 119.662\n",
      "Tempo corrente: 126.289\n",
      "Job: job2\n",
      "Tempo corrente: 8.67\n",
      "Tempo corrente: 8.763\n",
      "Tempo corrente: 8.605\n",
      "Tempo corrente: 8.744\n",
      "Tempo corrente: 8.992\n",
      "Tempo corrente: 9.059\n",
      "Tempo corrente: 9.632\n",
      "Tempo corrente: 9.723\n",
      "Tempo corrente: 9.838\n",
      "dati correnti [['SPARK_CORE', '1', 9.583, 11.824, 16.012, 18.426, 21.965, 25.213, 27.975, 29.687, 33.084], ['SPARK_CORE', '2', 7.117, 7.854, 10.562, 11.514, 12.986, 14.367, 15.415, 16.591, 18.521], ['HIVE', '1', 40.496, 55.58, 15.187, 119.261, 135.07, 152.103, 159.95, 212.162, 220.862], ['HIVE', '2', 40.339, 40.729, 43.746, 45.957, 50.375, 57.766, 62.777, 70.765, 75.734], ['MAP-REDUCE', '1', 5.65, 5.798, 6.739, 7.889, 8.955, 9.738, 11.674, 11.753, 12.765], ['MAP-REDUCE', '2', 3.058, 3.921, 4.065, 5.461, 5.77, 6.018, 6.861, 7.267, 7.698], ['SPARK-SQL', '1', 28.374, 41.22, 45.507, 53.927, 10.502, 16.997, 112.927, 119.662, 126.289], ['SPARK-SQL', '2', 8.67, 8.763, 8.605, 8.744, 8.992, 9.059, 9.632, 9.723, 9.838]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "columns=['System','job']+columns_view2\n",
    "print(\"NUMERO COLONNE:\",len(columns))\n",
    "data=[dati_SPARK_CORE,dati_HIVE,dati_MR,dati_SPARK_SQL]\n",
    "systems=['SPARK_CORE','HIVE','MAP-REDUCE','SPARK-SQL']\n",
    "\n",
    "create_dataset('tempi.csv',columns,data,systems)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
